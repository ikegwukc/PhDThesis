\relax 
\providecommand\hyper@newdestlabel[2]{}
\bibdata{thesisbib}
\bibcite{Backus59}{{1}{1959}{{Backus}}{{}}}
\bibcite{ML-UseCase1}{{2}{2018}{{{Bakshi} and {Bakshi}}}{{}}}
\bibcite{pedros:fewUsefulThings}{{3}{2012}{{Domingos}}{{}}}
\bibcite{feurer_auto_2018}{{4}{}{{Feurer et~al.}}{{Feurer, Klein, Eggensperger, Springenberg, Blum, and Hutter}}}
\bibcite{frank2005weka}{{5}{2005}{{Frank et~al.}}{{Frank, Hall, Holmes, Kirkby, Pfahringer, and Witten}}}
\bibcite{SML}{{6}{2017}{{Ikegwu et~al.}}{{Ikegwu, Hao, Asthana, and Brunner}}}
\bibcite{komer_hyperopt_2019}{{7}{}{{Komer et~al.}}{{Komer, Bergstra, and Eliasmith}}}
\bibcite{kotthoff_auto_2019}{{8}{}{{Kotthoff et~al.}}{{Kotthoff, Thornton, Hoos, Hutter, and Leyton-Brown}}}
\bibcite{Lichman:2013}{{9}{2013}{{Lichman}}{{}}}
\bibcite{Monahan}{{10}{2018}{{Monahan}}{{}}}
\bibcite{TPOT}{{11}{2016}{{Olson et~al.}}{{Olson, Bartley, Urbanowicz, and Moore}}}
\bibcite{scikit-learn}{{12}{2011}{{Pedregosa et~al.}}{{Pedregosa, Varoquaux, Gramfort, Michel, Thirion, Grisel, Blondel, Prettenhofer, Weiss, Dubourg, Vanderplas, Passos, Cournapeau, Brucher, Perrot, and Duchesnay}}}
\bibcite{RizzoloRo10}{{13}{2010}{{Rizzolo and Roth}}{{}}}
\bibcite{Roth05}{{14}{2005}{{Roth}}{{}}}
\citation{SML}
\citation{ML-UseCase1}
\citation{Monahan}
\citation{pedros:fewUsefulThings}
\citation{RizzoloRo10}
\citation{Roth05}
\@writefile{toc}{\contentsline {chapter}{Chapter\ 2\hskip 1em\relax Standard Machine Learning Language}{24}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Introduction}{24}{section.2.1}\protected@file@percent }
\newlabel{Introduction}{{2.1}{24}{Introduction}{section.2.1}{}}
\citation{TPOT}
\citation{kotthoff_auto_2019}
\citation{frank2005weka}
\citation{komer_hyperopt_2019}
\citation{scikit-learn}
\citation{feurer_auto_2018}
\citation{Backus59}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Prior Works}{25}{section.2.2}\protected@file@percent }
\newlabel{SML:PriorWorks}{{2.2}{25}{Prior Works}{section.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Grammar}{26}{section.2.3}\protected@file@percent }
\newlabel{grammar}{{2.3}{26}{Grammar}{section.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Grammar Structure}{26}{subsection.2.3.1}\protected@file@percent }
\newlabel{BNF:Query}{{2.1}{26}{Grammar Structure}{equation.2.3.1}{}}
\newlabel{BNF:Action}{{2.2}{26}{Grammar Structure}{equation.2.3.2}{}}
\newlabel{BNF:Option}{{2.3}{27}{Grammar Structure}{equation.2.3.3}{}}
\newlabel{BNF:OptionList}{{2.4}{27}{Grammar Structure}{equation.2.3.4}{}}
\newlabel{BNF:OptionValueList}{{2.5}{27}{Grammar Structure}{equation.2.3.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Keywords}{28}{subsection.2.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Reading Datasets}{28}{section*.17}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Cleaning Data}{28}{section*.18}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Partitioning Datasets}{28}{section*.19}\protected@file@percent }
\newlabel{SML:Dataflow}{{2}{28}{}{Hfootnote.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{Creating Models}{29}{section*.20}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Saving/Loading Models}{29}{section*.21}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Visualizing Datasets and Metrics of Algorithms}{29}{section*.22}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.4}SML's Architecture}{30}{section.2.4}\protected@file@percent }
\newlabel{sml-architecture}{{2.4}{30}{SML's Architecture}{section.2.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Interface}{30}{section.2.5}\protected@file@percent }
\newlabel{interface}{{2.5}{30}{Interface}{section.2.5}{}}
\citation{Lichman:2013}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Use Cases}{31}{section.2.6}\protected@file@percent }
\newlabel{use-cases}{{2.6}{31}{Use Cases}{section.2.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{Iris Dataset}{31}{section*.23}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Auto-Mpg Dataset}{32}{section*.24}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.1}Discussion}{32}{subsection.2.6.1}\protected@file@percent }
\newlabel{lab:iris:git}{{13}{32}{}{Hfootnote.16}{}}
\newlabel{lab:SML:AUTO}{{14}{32}{}{Hfootnote.17}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Future Work}{33}{section.2.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.8}Conclusion}{33}{section.2.8}\protected@file@percent }
\newlabel{conclusion}{{2.8}{33}{Conclusion}{section.2.8}{}}
\newlabel{SML:Github}{{15}{33}{}{Hfootnote.18}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.9}Figures and Listings}{35}{section.2.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9.1}Figures}{35}{subsection.2.9.1}\protected@file@percent }
\newlabel{RF1}{36}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Block Diagram of SML's Architecture \relax }}{36}{figure.caption.25}\protected@file@percent }
\newlabel{fig:SML:Architecture}{{2.1}{36}{Block Diagram of SML's Architecture\\\relax }{figure.caption.25}{}}
\newlabel{RF2}{37}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Block Diagram of SML's Connector \relax }}{37}{figure.caption.26}\protected@file@percent }
\newlabel{fig:SML:Connector}{{2.2}{37}{Block Diagram of SML's Connector\\\relax }{figure.caption.26}{}}
\newlabel{RF3}{38}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Interface of SML's website. Currently users can read instructions and examples of how to use SML are on the left pane. In the middle pane users can type an SML \(Query\) and then hit the execute button. The results of running the \(Query\) through SML are then displayed on the right pane. \relax }}{38}{figure.caption.27}\protected@file@percent }
\newlabel{fig:SML:website}{{2.3}{38}{Interface of SML's website. Currently users can read instructions and examples of how to use SML are on the left pane. In the middle pane users can type an SML \(Query\) and then hit the execute button. The results of running the \(Query\) through SML are then displayed on the right pane.\\\relax }{figure.caption.27}{}}
\newlabel{RF4}{39}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces The SML \(Query\) in Figure \ref  {fig:SML:IrisQuery} and the code in Figure \ref  {fig:Manual:IrisCode} produce these results. The subgraph on the left is a lattice plot showing the density estimates of each feature used. The graph on the right shows the ROC curves for each class of the iris dataset. \relax }}{39}{figure.caption.28}\protected@file@percent }
\newlabel{fig:IrisResults}{{2.4}{39}{The SML \(Query\) in Figure \ref {fig:SML:IrisQuery} and the code in Figure \ref {fig:Manual:IrisCode} produce these results. The subgraph on the left is a lattice plot showing the density estimates of each feature used. The graph on the right shows the ROC curves for each class of the iris dataset.\\\relax }{figure.caption.28}{}}
\newlabel{RF5}{40}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces The SML \(Query\) in Figure \ref  {fig:SML:AutoMPGQuery} and the code in Appendix B. produce these results. The subgraph on the left is a lattice plot showing the density estimates of each feature used. The top right graph shows the learning curve of the model and the graph on lower right shows the validation curve. \relax }}{40}{figure.caption.29}\protected@file@percent }
\newlabel{fig:AutoMPG:Results}{{2.5}{40}{The SML \(Query\) in Figure \ref {fig:SML:AutoMPGQuery} and the code in Appendix B. produce these results. The subgraph on the left is a lattice plot showing the density estimates of each feature used. The top right graph shows the learning curve of the model and the graph on lower right shows the validation curve.\\\relax }{figure.caption.29}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9.2}Listings}{41}{subsection.2.9.2}\protected@file@percent }
\newlabel{lst:sml-ex-1}{{2.1}{41}{Example of a SML Query Performing Classification}{lstlisting.2.1}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {2.1}Example of a SML Query Performing Classification.}{41}{lstlisting.2.1}\protected@file@percent }
\newlabel{lst:SML:BNFComp}{{2.2}{41}{Here the example \(Query\) in listing \ref {lst:sml-ex-1} is defined in BNF format}{lstlisting.2.2}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {2.2}Here the example \(Query\) in listing \ref  {lst:sml-ex-1} is defined in BNF format.}{41}{lstlisting.2.2}\protected@file@percent }
\newlabel{lst:SML:READ}{{2.3}{41}{Examples using the \(READ\) \(Keyword\) in SML}{lstlisting.2.3}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {2.3}Examples using the \(READ\) \(Keyword\) in SML.}{41}{lstlisting.2.3}\protected@file@percent }
\newlabel{lst:SML:REPLACE}{{2.4}{41}{An example utilizing the \(REPLACE\) \(Keyword\) in SML}{lstlisting.2.4}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {2.4}An example utilizing the \(REPLACE\) \(Keyword\) in SML.}{41}{lstlisting.2.4}\protected@file@percent }
\newlabel{lst:SML:SPLIT}{{2.5}{41}{Example using the \(SPLIT\) \(Keyword\) in SML}{lstlisting.2.5}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {2.5}Example using the \(SPLIT\) \(Keyword\) in SML.}{41}{lstlisting.2.5}\protected@file@percent }
\newlabel{lst:SML:CLASSIFY}{{2.6}{41}{Example using the \(CLASSIFY\) \(Keyword\) in SML. Here we read in data and create training and testing datasets using the \(READ\) and \(SPLIT\) \(Keyword\)s respectively. We then use \(CLASSIFY\) \(Keyword\) with the first 4 columns as features and the 5th column to perform classification using a support vector machine}{lstlisting.2.6}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {2.6}Example using the \(CLASSIFY\) \(Keyword\) in SML. Here we read in data and create training and testing datasets using the \(READ\) and \(SPLIT\) \(Keyword\)s respectively. We then use \(CLASSIFY\) \(Keyword\) with the first 4 columns as features and the 5th column to perform classification using a support vector machine.}{41}{lstlisting.2.6}\protected@file@percent }
\newlabel{lst:SML:CLUSTER}{{2.7}{42}{Example using the CLUSTER Keyword in SML. Here we read in data and create training and testing datasets using the READ and SPLIT Keywords respectively. We then use CLUSTER Keyword with the first 4 columns as features and perform unsupervised clustering with the K-Means algorithm}{lstlisting.2.7}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {2.7}Example using the CLUSTER Keyword in SML. Here we read in data and create training and testing datasets using the READ and SPLIT Keywords respectively. We then use CLUSTER Keyword with the first 4 columns as features and perform unsupervised clustering with the K-Means algorithm.}{42}{lstlisting.2.7}\protected@file@percent }
\newlabel{lst:SML:REGRESS}{{2.8}{42}{Example using the \(REGRESS\) \(Keyword\) in SML. Here we read in data and create training and testing datasets using the \(READ\) and \(SPLIT\) \(Keyword\)s respectively. We then use \(REGRESS\) \(Keyword\) with the first 4 columns as features and the 5th column to perform regression on using ridge regression}{lstlisting.2.8}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {2.8}Example using the \(REGRESS\) \(Keyword\) in SML. Here we read in data and create training and testing datasets using the \(READ\) and \(SPLIT\) \(Keyword\)s respectively. We then use \(REGRESS\) \(Keyword\) with the first 4 columns as features and the 5th column to perform regression on using ridge regression.}{42}{lstlisting.2.8}\protected@file@percent }
\newlabel{lst:SML:SAVE_LOAD}{{2.9}{42}{Example using the \(LOAD\) and \(SAVE\) \(Keyword\)s in SML}{lstlisting.2.9}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {2.9}Example using the \(LOAD\) and \(SAVE\) \(Keyword\)s in SML.}{42}{lstlisting.2.9}\protected@file@percent }
\newlabel{lst:SML:PLOT}{{2.10}{42}{Example using the \(PLOT\) \(Keyword\) in SML}{lstlisting.2.10}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {2.10}Example using the \(PLOT\) \(Keyword\) in SML.}{42}{lstlisting.2.10}\protected@file@percent }
\newlabel{lst:SML:IrisQuery}{{2.11}{42}{SML \(Query\) that performs classification on the iris dataset using support vector machines. It's important to note that detailed documentation is publicly available in \textsuperscript {\ref {lab:iris:git}} and the purpose of this figure is to highlight the level of the level of complexity relative to an SML query}{lstlisting.2.11}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {2.11}SML \(Query\) that performs classification on the iris dataset using support vector machines. It's important to note that detailed documentation is publicly available in \textsuperscript  {\ref  {lab:iris:git}} and the purpose of this figure is to highlight the level of the level of complexity relative to an SML query.}{42}{lstlisting.2.11}\protected@file@percent }
\newlabel{lst:SML:AutoMPGQuery}{{2.12}{43}{SML \(Query\) that performs regression on the Auto-MPG dataset using Linear Regression}{lstlisting.2.12}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {2.12}SML \(Query\) that performs regression on the Auto-MPG dataset using Linear Regression.}{43}{lstlisting.2.12}\protected@file@percent }
\bibstyle{plainnat}
\bibdata{thesisbib}
\bibcite{Backus59}{{1}{1959}{{Backus}}{{}}}
\bibcite{ML-UseCase1}{{2}{2018}{{{Bakshi} and {Bakshi}}}{{}}}
\bibcite{pedros:fewUsefulThings}{{3}{2012}{{Domingos}}{{}}}
\bibcite{feurer_auto_2018}{{4}{}{{Feurer et~al.}}{{Feurer, Klein, Eggensperger, Springenberg, Blum, and Hutter}}}
\bibcite{frank2005weka}{{5}{2005}{{Frank et~al.}}{{Frank, Hall, Holmes, Kirkby, Pfahringer, and Witten}}}
\bibcite{SML}{{6}{2017}{{Ikegwu et~al.}}{{Ikegwu, Hao, Asthana, and Brunner}}}
\bibcite{komer_hyperopt_2019}{{7}{}{{Komer et~al.}}{{Komer, Bergstra, and Eliasmith}}}
\bibcite{kotthoff_auto_2019}{{8}{}{{Kotthoff et~al.}}{{Kotthoff, Thornton, Hoos, Hutter, and Leyton-Brown}}}
\bibcite{Lichman:2013}{{9}{2013}{{Lichman}}{{}}}
\bibcite{Monahan}{{10}{2018}{{Monahan}}{{}}}
\bibcite{TPOT}{{11}{2016}{{Olson et~al.}}{{Olson, Bartley, Urbanowicz, and Moore}}}
\bibcite{scikit-learn}{{12}{2011}{{Pedregosa et~al.}}{{Pedregosa, Varoquaux, Gramfort, Michel, Thirion, Grisel, Blondel, Prettenhofer, Weiss, Dubourg, Vanderplas, Passos, Cournapeau, Brucher, Perrot, and Duchesnay}}}
\@writefile{toc}{\contentsline {section}{\numberline {2.10}References}{44}{section.2.10}\protected@file@percent }
\bibcite{RizzoloRo10}{{13}{2010}{{Rizzolo and Roth}}{{}}}
\bibcite{Roth05}{{14}{2005}{{Roth}}{{}}}
\@setckpt{2-SML}{
\setcounter{page}{46}
\setcounter{equation}{5}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{15}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{10}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{5}
\setcounter{table}{0}
\setcounter{NAT@ctr}{14}
\setcounter{parentequation}{0}
\setcounter{Item}{0}
\setcounter{Hfootnote}{18}
\setcounter{bookmark@seq@number}{27}
\setcounter{caption@flags}{0}
\setcounter{continuedfloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{r@tfl@t}{5}
\setcounter{lstnumber}{9}
\setcounter{FancyVerbLine}{0}
\setcounter{AlgoLine}{0}
\setcounter{algocfline}{0}
\setcounter{algocfproc}{0}
\setcounter{algocf}{0}
\setcounter{@pps}{0}
\setcounter{@ppsavesec}{0}
\setcounter{@ppsaveapp}{0}
\setcounter{section@level}{1}
\setcounter{lstlisting}{12}
}
