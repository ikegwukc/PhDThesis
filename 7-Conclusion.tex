\chapter{Conclusion}


\section{Summary and Conclusion}

% SML Chapter
In Chapter \ref{Chapter:SML}, we introduced SML, a programming language agnostic framework that integrates a query-like language to simplify the development of machine learning pipelines.   We provided a high level overview of it’s architecture and grammar. We applied SML to several well-known machine learning problems and demonstrated the benefits of this new approach, such as how the amount of code one has to write significantly decreases when using SML.  

In the future, we can extend the connector in SML's architecture to support more machine learning libraries and additional programming languages.  We also can extend SML’s web application to include additional functionality to improve the ease of use.  Feature selection, model selection, and parameter optimization are additional areas that can be added to SML. In addition to improving SML itself, we also can perform more comparative analyses as tests against similar works.  

% ABIS Chapter
In Chapter \ref{Chapter:ABIS}, we used random forest trees in a supervised learning paradigm to predict the annual direction of profitability for firms with minimal information.  We generated out-of-sample predictions of directional changes (increases or decreases) in five profitability measures: return on equity (ROE), return on assets (ROA), return on net operating assets (RNOA), cash flow from operations (CFO), and free cash flow (FCF) from 2011-2016. We found that the classification accuracy for each measure outperformed  random walk models.

We can further improve the classification accuracies by selecting a model that yields better performance but offers less interpretability.  Given that we focus on a minimal set of features in this research, we can incorporate additional features for additional performance gains. With more observations, we can also extend the methodology outlined in this paper to a regression setting and make predictions about the magnitudes of profitability.

% PyIF Chapter
In Chapter \ref{Chapter:PyIF}, we develop a new software package to estimate bi-variate transfer entropy  (TE).  Our method scaled better to larger data than existing implementations.  On large data, our implementation, PyIF, is up to 1072 times faster utilizing GPUs and up to 181 times faster utilizing CPUs than existing implementations that estimate bi-variate TE. For future work, we plan to improve the existing code base to improve the computational performance of PyIF.  In addition to this, we plan to implement additional estimators to estimate bi-variate TE.


% Earnings TE Chapter

In Chapter \ref{Chapter:EATE}, we introduced a new approach to examine information transfers around corporate earnings announcements.  We studied the network effect of earnings announcements by constructing daily networks of pairwise cross-firm information transfers. Our approach to construct this network relies on non-parametric estimates in equity prices with measures of transfer entropy drawn from information theory.  We provide evidence that earnings information produced by a single firm flows to other firms across industries.  Results from our tests showed that cross-firm links are substantially stronger for firms on days with releases of earnings information and for firms with more unexpected earnings news.

\RC{Made several big changes in this next paragraph. Please verify.}

% hat cross-firm links are more likely for firms with a shared industry, 
Further,  we found that communities of firms in the network also form between firms with links that are not adequately captured by characteristics as defined by the existing literature.  We plan to develop community detection algorithms to work in very dense weighted networks such as our information transfer networks as a  future work.  We also plan to explore the utility of information transfers for market performance predictions.



%\clearpage
%\bibliographystyle{plainnat}
%\bibliography{thesisbib}

\bibliographystyle{plainnat}
\nobibliography{thesisbib}